{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Estudio comparativo de algoritmos en un problema de k-armed bandit\n",
    "\n",
    "*Descrition:* El experimento compara el rendimiento de algoritmos epsilon-greedy en un problema de k-armed bandit.\n",
    "Se generan gráficas de recompensas promedio y selecciones óptimas para cada algoritmo.\n",
    "\n",
    "_Author: Luis Daniel Hernández Molinero_\n",
    "_Email: ldaniel@um.es_\n",
    "_Date: 2025/01/29_\n",
    "\n",
    "This software is licensed under the GNU General Public License v3.0 (GPL-3.0),\n",
    "with the additional restriction that it may not be used for commercial purposes.\n",
    "\n",
    "For more details about GPL-3.0: https://www.gnu.org/licenses/gpl-3.0.html\n",
    "\n"
   ],
   "id": "45718ddbdacc17ac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Copiar el repositorio\n",
    "import os\n",
    "from shutil import rmtree\n",
    "import sys\n",
    "\n",
    "# Cambiar al directorio /content\n",
    "os.chdir('/content')\n",
    "\n",
    "# Verificar si el directorio existe antes de borrarlo\n",
    "if os.path.exists(\"k_bandits\"):  # Asegurar de que el directorio se corresopnde al github\n",
    "    rmtree(\"k_bandits\")\n",
    "\n",
    "!git clone https://github.com/ldaniel-hm/k_bandits.git\n",
    "# Navegar al directorio del proyecto\n",
    "os.chdir('k_bandits')\n",
    "!pwd\n",
    "!ls\n",
    "\n",
    "# Añadir los directorio fuentes al path de Python\n",
    "sys.path.append('/content/algorithms')\n",
    "sys.path.append('/content/arms')\n",
    "\n",
    "# Verificar que se han añadido correctamente\n",
    "print(sys.path)"
   ],
   "id": "bf5905976fb24fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#@title Importamos todas las clases y funciones\n",
    "\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "from algorithms import Algorithm, EpsilonGreedy\n",
    "from arms import ArmNormal, Bandit\n",
    "from plotting import plot_average_rewards, plot_optimal_selections\n"
   ],
   "id": "4582eec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def run_experiment(bandit: Bandit, algorithms: List[Algorithm], steps: int, runs: int):\n",
    "\n",
    "    optimal_arm = bandit.optimal_arm\n",
    "\n",
    "    rewards = np.zeros((len(algorithms), steps))\n",
    "    optimal_selections = np.zeros((len(algorithms), steps))\n",
    "\n",
    "    for run in range(runs):\n",
    "        current_bandit = Bandit(arms=bandit.arms)\n",
    "        q_max = current_bandit.get_expected_value(current_bandit.optimal_arm)\n",
    "\n",
    "        for algo in algorithms:\n",
    "            algo.reset()\n",
    "\n",
    "        total_rewards_per_algo = np.zeros(len(algorithms))\n",
    "\n",
    "        for step in range(steps):\n",
    "            for idx, algo in enumerate(algorithms):\n",
    "                chosen_arm = algo.select_arm()\n",
    "                reward = current_bandit.pull_arm(chosen_arm)\n",
    "                algo.update(chosen_arm, reward)\n",
    "\n",
    "                rewards[idx, step] += reward\n",
    "                total_rewards_per_algo[idx] += reward\n",
    "\n",
    "                if chosen_arm == optimal_arm:\n",
    "                    optimal_selections[idx, step] += 1\n",
    "\n",
    "    rewards /= runs\n",
    "    optimal_selections = (optimal_selections / runs) * 100\n",
    "\n",
    "    return rewards, optimal_selections\n"
   ],
   "id": "7377ca48ee0f5946"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bf5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parámetros del experimento\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "k = 10  # Número de brazos\n",
    "steps = 1000  # Número de pasos\n",
    "runs = 500  # Número de ejecuciones\n",
    "\n",
    "# Creación del bandit\n",
    "bandit = Bandit(arms=ArmNormal.generate_arms(k))\n",
    "print(bandit)\n",
    "\n",
    "optimal_arm = bandit.optimal_arm\n",
    "print(f\"Optimal arm: {optimal_arm + 1} with expected reward={bandit.get_expected_value(optimal_arm)}\")\n",
    "\n",
    "# Definir los algoritmos a comparar\n",
    "algorithms = [EpsilonGreedy(k=k, epsilon=0), EpsilonGreedy(k=k, epsilon=0.01), EpsilonGreedy(k=k, epsilon=0.1)]\n",
    "\n",
    "# Ejecutar el experimento\n",
    "rewards, optimal_selections = run_experiment(bandit, algorithms, steps, runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graficar los resultados\n",
    "plot_average_rewards(steps, rewards, algorithms)\n",
    "# plot_optimal_selections(steps, optimal_selections, algorithms)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
